{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e2366a9",
   "metadata": {},
   "source": [
    "#  Forward Feature Selection\n",
    "Forward Elimination is a type of wrapper-based feature selection method where features are added one at a time to the model based on their ability to improve performance (e.g., accuracy, F1 score, R²)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6e0fac",
   "metadata": {},
   "source": [
    "### What is Forward Elimination?\n",
    "- Forward Elimination starts with no features and iteratively adds the most significant features, one by one, until adding more features does not improve model performance significantly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb45b402",
   "metadata": {},
   "source": [
    "### Step-by-Step Working of Forward Elimination\n",
    "- Step 1: Start with zero features.\n",
    "- Step 2: Train the model using each individual feature.\n",
    "- Step 3: Select the feature that improves the model the most (based on evaluation metric).\n",
    "- Step 4: Add that feature to the selected set.\n",
    "- Step 5: Repeat steps 2–4 by adding one new feature at a time from the remaining pool.\n",
    "- Step 6: Stop when: a) No further improvement; b) Maximum number of features reached, or; c) A performance threshold is met."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd524c23",
   "metadata": {},
   "source": [
    "#  Forward Feature Selection Using MLxtend\n",
    "MLxtend (Machine Learning Extensions) is a Python library that provides powerful tools for feature selection, including Forward Feature Selection (Forward Elimination) with cross-validation support."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb58a28",
   "metadata": {},
   "source": [
    "###  What is Forward Elimination in MLxtend?\n",
    "In MLxtend, forward selection is implemented using:\n",
    "```\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "```\n",
    "- This function adds one feature at a time to the model, selecting the feature that improves the performance the most (based on a scoring metric), until a predefined number of features is selected or no further improvement is observed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22edeec9",
   "metadata": {},
   "source": [
    "``` bash\n",
    "# Example Format\n",
    "# Initialize Forward Selector\n",
    "sfs = SFS(log_reg,     # the modeal defined in the variable as estimator\n",
    "          k_features='best',      # select best number of features (can also be an int like 3)\n",
    "          forward=True,           # Forward selection\n",
    "          floating=False,         # No backward steps\n",
    "          scoring='accuracy',     # Metric to evaluate performance\n",
    "          cv=5,                   # 5-fold cross-validation\n",
    "          n_jobs=-1               # Use all CPUs\n",
    "         )\n",
    "```\n",
    "- Mostly we use estimator (model), k_features = 'Depends how many you want to select', forword = 'Ture/False' (Depends which type of feature selection you are doing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16bfc22",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bdee8d",
   "metadata": {},
   "source": [
    "# Backward Feature Selection\n",
    "Backward Feature Selection is a wrapper-based technique for feature selection where the process begins with all features, and features are eliminated one at a time based on their insignificance until the best subset remains."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791c3a0b",
   "metadata": {},
   "source": [
    "### What is Backward Feature Selection?\n",
    "- It is an iterative method that starts with all features in the dataset and removes the least important feature at each step, based on model performance (e.g., p-value, accuracy, R²), until a stopping criterion is met."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666e3631",
   "metadata": {},
   "source": [
    "### Steps in Backward Feature Selection\n",
    "- Step 1:Start with all features.\n",
    "- Step 2:Fit the model on the training data.\n",
    "- Step 3:Evaluate performance metric or statistical test for each feature.\n",
    "- Step 4:Remove the least important feature (e.g., highest p-value or least impact).\n",
    "- Step 5:Repeat steps 2–4 until: a) A desired number of features is reached; b) Model performance stops improving; c) All remaining features are statistically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0cbd59",
   "metadata": {},
   "source": [
    "# Backward Feature Selection using MLxtend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3761950",
   "metadata": {},
   "source": [
    "- Backward Feature Selection, also called Backward Elimination, is supported in MLxtend through the SequentialFeatureSelector class by setting forward=False.\n",
    "- MLxtend allows this process to be done easily, with cross-validation, any estimator, and support for performance visualization.\n",
    "\n",
    "- In MLxtend, backword selection is implemented using:\n",
    "```\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2dc1b7",
   "metadata": {},
   "source": [
    "``` bash\n",
    "# Example Format\n",
    "sfs = SFS(estimator=model,\n",
    "          k_features='best',      # Can also be an integer like 5\n",
    "          forward=False,          # ← BACKWARD Selection as you have used False there\n",
    "          floating=False,         # Set True for SFFS (optional)\n",
    "          scoring='r2',           # You can use 'neg_mean_squared_error' or others\n",
    "          cv=5,                   # 5-fold cross-validation\n",
    "          n_jobs=-1)              # Use all CPU cores\n",
    "```\n",
    "- Mostly we use estimator (model), k_features = 'Depends how many you want to select', forword = 'Ture/False' (Depends which type of feature selection you are doing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffab0314",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201bff9d",
   "metadata": {},
   "source": [
    "### Key Parameters of SequentialFeatureSelector\n",
    "\n",
    "| Parameter    | Description                                                |\n",
    "| ------------ | ---------------------------------------------------------- |\n",
    "| `estimator`  | Your ML model (LogisticRegression, RandomForest, etc.)     |\n",
    "| `k_features` | Number of features to select or `'best'`                   |\n",
    "| `forward`    | `True` = forward selection; `False` = backward elimination |\n",
    "| `floating`   | Enables stepwise (adds and removes features)               |\n",
    "| `scoring`    | Scoring metric (`'accuracy'`, `'r2'`, etc.)                |\n",
    "| `cv`         | Number of cross-validation folds                           |\n",
    "| `n_jobs`     | Parallel processing (set to -1 for all cores)              |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e37d83b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b7cc4c",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e780984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8325f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>Customer_Segment</th>\n",
       "      <th>Sales_Before</th>\n",
       "      <th>Sales_After</th>\n",
       "      <th>Customer_Satisfaction_Before</th>\n",
       "      <th>Customer_Satisfaction_After</th>\n",
       "      <th>Purchase_Made</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Control</td>\n",
       "      <td>High Value</td>\n",
       "      <td>240.548359</td>\n",
       "      <td>300.007568</td>\n",
       "      <td>74.684767</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Treatment</td>\n",
       "      <td>High Value</td>\n",
       "      <td>246.862114</td>\n",
       "      <td>381.337555</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Control</td>\n",
       "      <td>High Value</td>\n",
       "      <td>156.978084</td>\n",
       "      <td>179.330464</td>\n",
       "      <td>98.780735</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Control</td>\n",
       "      <td>Medium Value</td>\n",
       "      <td>192.126708</td>\n",
       "      <td>229.278031</td>\n",
       "      <td>49.333766</td>\n",
       "      <td>39.811841</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>High Value</td>\n",
       "      <td>229.685623</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.974852</td>\n",
       "      <td>87.738591</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Group Customer_Segment  Sales_Before  Sales_After  \\\n",
       "0    Control       High Value    240.548359   300.007568   \n",
       "1  Treatment       High Value    246.862114   381.337555   \n",
       "2    Control       High Value    156.978084   179.330464   \n",
       "3    Control     Medium Value    192.126708   229.278031   \n",
       "4        NaN       High Value    229.685623          NaN   \n",
       "\n",
       "   Customer_Satisfaction_Before  Customer_Satisfaction_After Purchase_Made  \n",
       "0                     74.684767                          NaN            No  \n",
       "1                    100.000000                   100.000000           Yes  \n",
       "2                     98.780735                   100.000000            No  \n",
       "3                     49.333766                    39.811841           Yes  \n",
       "4                     83.974852                    87.738591           Yes  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load The dataset\n",
    "ds = pd.read_csv('Sales_data.csv')\n",
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90fdeeaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 6)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data into x axis and y axis\n",
    "x = ds.iloc[:, :-1]\n",
    "y = ds['Purchase_Made'] \n",
    "x.shape   # to get the total number of featueres in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583e8a86",
   "metadata": {},
   "source": [
    "##### Have to preprocess the in order to work on the model (Will do it later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2de71c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the model\n",
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f765cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection\n",
    "sfs = SequentialFeatureSelector(lr, k_features = 5, forward= True)  # Here, I have used forword feature selection method\n",
    "sfs.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd4309c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Features (selected and original)\n",
    "print(sfs.feature_names)  # original featues\n",
    "print(sfs.k_feature_names_)   # Selected Features using forword feature selection\n",
    "sfs.k_score_   # The score of the model (accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54725168",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61defd1",
   "metadata": {},
   "source": [
    "### ChatGPT Based Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c6a5f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8f7b1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "data = load_diabetes()\n",
    "X = data.data\n",
    "y = data.target\n",
    "feature_names = data.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e23d6bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "090b3095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Model\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485becd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection with MLxtent\n",
    "# sfs = SFS(model, k_features= 6, forward=False)  # Backword Feature Selection \n",
    "sfs = SFS(model, k_features= 6, forward=True)   # forword Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07bccaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs = sfs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5890ba40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Original Feature names\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26afcc5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sex', 'bmi', 'bp', 's1', 's3', 's5']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selected Feature Names\n",
    "[feature_names[i] for i in sfs.k_feature_idx_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0594b6a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.45273020610465514)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfs.k_score_   # Based on this score I have will set the number of feature i have to select (max values we have to take so based on that try multiple features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36ae33e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test R² Score: 0.48163855615378837\n"
     ]
    }
   ],
   "source": [
    "# Transform training and testing sets\n",
    "X_train_selected = sfs.transform(X_train)\n",
    "X_test_selected = sfs.transform(X_test)\n",
    "\n",
    "# Train model on selected features\n",
    "model.fit(X_train_selected, y_train)\n",
    "y_pred = model.predict(X_test_selected)\n",
    "\n",
    "print(\"Test R² Score:\", r2_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
