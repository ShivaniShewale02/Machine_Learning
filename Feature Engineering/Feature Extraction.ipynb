{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06cade77",
   "metadata": {},
   "source": [
    "# Feature Extraction in Machine Learning\n",
    "Feature Extraction is the process of transforming raw data into numerical or symbolic features that can be used by machine learning algorithms. It is especially important when working with high-dimensional, unstructured, or complex data such as text, images, or time series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c047292d",
   "metadata": {},
   "source": [
    "## üìå What is Feature Extraction?\n",
    "- Feature Extraction is the process of converting input data into a set of measurable and informative features. \n",
    "- These features should represent the underlying structure or pattern in the data while reducing dimensionality and retaining important information.\n",
    "- üß† Goal: Extract informative features that improve model performance and reduce noise or redundancy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e84a692",
   "metadata": {},
   "source": [
    "### üîç Why Feature Extraction is Important?\n",
    "\n",
    "| Benefit                          | Description                                     |\n",
    "| -------------------------------- | ----------------------------------------------- |\n",
    "| üßπ Reduces dimensionality        | Helps in compressing the data                   |\n",
    "| üéØ Enhances model performance    | Removes irrelevant or redundant data            |\n",
    "| üîç Improves interpretability     | Converts raw input into understandable features |\n",
    "| ‚öôÔ∏è Required for non-tabular data | Text, image, audio must be vectorized           |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ee547c",
   "metadata": {},
   "source": [
    "# Types of Feature Extraction (Based on Data Type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0433e9d0",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ For Text Data (NLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7a9bbd",
   "metadata": {},
   "source": [
    "#### üîπ Bag of Words (BoW)\n",
    "- Counts the number of times each word appears in a document.\n",
    "- Ignores grammar and word order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3027983a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fb0f36",
   "metadata": {},
   "source": [
    "#### üîπ TF-IDF (Term Frequency-Inverse Document Frequency)\n",
    "- Highlights important words by reducing weight of common terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2838d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "X = tfidf.fit_transform(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf732548",
   "metadata": {},
   "source": [
    "#### üîπ Word Embeddings\n",
    "- Converts words to dense vectors preserving meaning (semantic similarity).\n",
    "\n",
    "| Method   | Description                                             |\n",
    "| -------- | ------------------------------------------------------- |\n",
    "| Word2Vec | Vectorizes based on surrounding context                 |\n",
    "| GloVe    | Combines global matrix factorization with local context |\n",
    "| BERT     | Contextual word representation                          |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250f0dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example \n",
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec(sentences, vector_size=100)\n",
    "vector = model.wv['machine']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3eeb83",
   "metadata": {},
   "source": [
    "#### üîπ Other NLP Features\n",
    "| Feature                              | Description                   |\n",
    "| ------------------------------------ | ----------------------------- |\n",
    "| Text length                          | Number of characters or words |\n",
    "| Count of specific POS (nouns, verbs) | Linguistic structure          |\n",
    "| Sentiment score                      | Polarity of sentiment         |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244e883e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69070059",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ For Image Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea63953a",
   "metadata": {},
   "source": [
    "#### üîπ Raw Pixel Values\n",
    "- Flatten the image matrix (e.g., 28x28 becomes 784 features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378bc98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "pixels = image.reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dcdf7c",
   "metadata": {},
   "source": [
    "#### üîπ Histogram of Oriented Gradients (HOG)\n",
    "- Captures edge directions and shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a989c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "from skimage.feature import hog\n",
    "features, _ = hog(image, visualize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f11970",
   "metadata": {},
   "source": [
    "#### üîπ Color Histograms\n",
    "- Extract color distribution in the image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec024dc",
   "metadata": {},
   "source": [
    "#### üîπ Deep Learning Feature Extraction (CNN)\n",
    "- Use pre-trained models (VGG16, ResNet, etc.) to extract features from intermediate layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445410dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Code\n",
    "from tensorflow.keras.applications import VGG16\n",
    "model = VGG16(include_top=False, weights='imagenet')\n",
    "features = model.predict(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e431c0d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ba733d",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ For Audio Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147719af",
   "metadata": {},
   "source": [
    "#### üîπ MFCC (Mel-Frequency Cepstral Coefficients)\n",
    "- Captures the timbral aspects of audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16485e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Code\n",
    "import librosa\n",
    "mfcc = librosa.feature.mfcc(y=audio, sr=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a39f3c",
   "metadata": {},
   "source": [
    "#### üîπ Chroma Features\n",
    "- Represents energy of 12 distinct semitone pitches.\n",
    "\n",
    "#### üîπ Spectral Features\n",
    "- Includes spectral centroid, roll-off, flux, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef38b4f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f1ac2c",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ For Time Series Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f9b1e6",
   "metadata": {},
   "source": [
    "#### üîπ Lag Features\n",
    "- Previous values used as input.\n",
    "\n",
    "#### üîπ Rolling Statistics\n",
    "- Moving averages, rolling mean, min, std.\n",
    "\n",
    "#### üîπ Fourier / Wavelet Transforms\n",
    "- Converts time domain to frequency domain.\n",
    "\n",
    "#### üîπ Autocorrelation Features\n",
    "- Captures relationship of current value with its past values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99857d5e",
   "metadata": {},
   "source": [
    "#### üîπ tsfresh / Kats\n",
    "- Python libraries for automatic time series feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4717d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Code\n",
    "from tsfresh import extract_features\n",
    "features = extract_features(df, column_id='id', column_sort='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9deac807",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13786f9",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ For Tabular Data\n",
    "Even tabular data may benefit from:\n",
    "\n",
    "- PCA (Principal Component Analysis)\n",
    "- ICA (Independent Component Analysis)\n",
    "- Autoencoders (deep learning-based)\n",
    "- t-SNE / UMAP (for visualization, not modeling)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8a8b41",
   "metadata": {},
   "source": [
    "### üì¶ Libraries for Feature Extraction\n",
    "\n",
    "| Data Type   | Libraries                                             |\n",
    "| ----------- | ----------------------------------------------------- |\n",
    "| Text        | `sklearn`, `nltk`, `spacy`, `gensim`                  |\n",
    "| Image       | `OpenCV`, `scikit-image`, `tensorflow`, `torchvision` |\n",
    "| Audio       | `librosa`, `pyAudioAnalysis`                          |\n",
    "| Time Series | `tsfresh`, `kats`, `sktime`                           |\n",
    "| General     | `sklearn.decomposition`, `autoencoders`               |"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
